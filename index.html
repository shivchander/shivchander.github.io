<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Shivchander Sudalairaj</title>

    <meta name="author" content="Shivchander Sudalairaj">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Shivchander Sudalairaj
                </p>
                <p>I'm a Senior Research Engineer and a founding member of the <a href="https://code.xuk.ai/instructlab-research/">AI Innovation Team</a> at <a href="https://www.redhat.com/en/products/ai">Red Hat AI</a> and <a href="https://mitibmwatsonailab.mit.edu/">MIT-IBM Watson AI Lab</a> in Boston. At Red Hat, I lead the research front of Synthetic Data Generation (SDG) component of RHEL AI, a platform designed to customize and operationalize large language models (LLMs) for diverse enterprise applications. My work focuses on integrating foundational models into enterprise workflows, driving innovation across Red Hat's AI product ecosystem. At IBM, I'm part of the core Alignment Team, responsible for aligning and training IBM's generative AI systems, including co-inventing key projects like InstructLab and Synderella. These efforts form the backbone of the generative AI strategy for both IBM and Red Hat.</p>
                <p>
                  I completed my M.S. in Computer Science at the University of Cincinnati, where I worked on spatio-temporal analysis of EEG using deep learning under the guidance of Prof. Anca Ralescu. During my undergraduate studies at the same institution, I explored fine-grained prediction of topical stance and political leaning from Twitter, earning honors like Magna Cum Laude and Dean's List recognition. My educational journey was supported by an <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1936908">NSF Grant</a>, and I remain passionate about advancing the frontiers of AI and its applications in real-world contexts.
                </p>
                <p style="text-align:center">
                  <a href="mailto:shivchan@mit.edu">Email</a> &nbsp;/&nbsp;
                  <a href="data/shiv_CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=O71amfMAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/shivsr98">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/shivchander">Github</a>
                </p>
              </td>
              <td style="padding: 2.5%; width: 40%; max-width: 40%; text-align: center;">
                <a href="images/shiv.jpg">
                  <img 
                    style="
                      width: 100%; 
                      max-width: 200px; 
                      height: auto; 
                      aspect-ratio: 1; 
                      object-fit: cover; 
                      border-radius: 15%; 
                      box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1); 
                      border: 2px solid #e0e0e0;
                    " 
                    alt="profile photo" 
                    src="images/shiv.jpg" 
                    class="hoverZoomLink"
                  >
                </a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  My research focuses on generative AI, particularly large language models (LLMs), synthetic data generation, and AI customization for enterprise applications. I am passionate about creating scalable, privacy-preserving solutions and adapting foundation models to solve real-world challenges across diverse domains.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/papers/cdr.png' alt="CDR" style="width:100%;max-width:200px;object-fit:cover;border-radius:15%;box-shadow:0px 4px 6px rgba(0, 0, 0, 0.1);">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2411.02481">
                      <span class="papertitle">CDR: Customizable Density Ratios of Strong-over-weak LLMs for Preference Annotation</span>
                  </a>
                  <br>
                  <a href="https://scholar.google.com/citations?user=ohsEWqsAAAAJ&hl=en">Guangxuan Xu</a>, 
                  <a href="https://xuk.ai">Kai Xu</a>, 
                  <a href="https://shivchander.github.io"><strong>Shivchander Sudalairaj</strong></a>, 
                  <a href="https://haowang94.github.io">Hao Wang</a>, 
                  <a href="https://akashgit.github.io/">Akash Srivastava</a>
                  <br>
                  <em>ICLR</em>, 2025 <span style="font-size: small;">(Under Review)</span>
                  <br>
                  <p>
                    Preference tuning of large language models (LLMs) often relies on costly human data or proprietary models. CDR (Customized Density Ratio) introduces a training-free approach that uses off-the-shelf LLMs to generate preference data by leveraging the log-density ratio between better-aligned and less-aligned models.
                  </p>
              </td>
          </tr>

          <tr style="background-color: #ffe9c6; border-radius: 10px;">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/papers/lab.png' alt="LAB: Large-Scale Alignment for ChatBots" style="width:100%;max-width:200px;object-fit:cover;border-radius:15%;box-shadow:0px 4px 6px rgba(0, 0, 0, 0.1);">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2403.01081">
                    <span class="papertitle">LAB: Large-Scale Alignment for ChatBots</span>
                </a>
                <br>
                <a href="https://shivchander.github.io"><strong>Shivchander Sudalairaj</strong></a><sup>*</sup>,
                <a href="https://scholar.google.com/citations?user=lV0gYnkAAAAJ&hl=en">Abhishek Bhandwaldar</a>, 
                <a href="https://scholar.google.com/citations?user=Qpl3KlIAAAAJ&hl=en">Aldo Pareja</a>, 
                <a href="https://xuk.ai">Kai Xu</a>, 
                <a href="https://mitibmwatsonailab.mit.edu/people/david-cox/">David D. Cox</a>, 
                <a href="https://akashgit.github.io/">Akash Srivastava</a><sup>*</sup>
                <br>
                <p>
                    LAB (Large-scale Alignment for chatBots) introduces a scalable methodology for instruction-tuning large language models (LLMs) using taxonomy-guided synthetic data generation and a multi-phase tuning framework. It reduces dependency on costly human annotations and proprietary models like GPT-4, and provides a framework for customizing small language models.
                </p>
            </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/papers/graft.png' alt="Grafting Vision Transformers" style="width:100%;max-width:200px;object-fit:cover;border-radius:15%;box-shadow:0px 4px 6px rgba(0, 0, 0, 0.1);">
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2210.15943">
                  <span class="papertitle">Grafting Vision Transformers</span>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?user=qIn5k_sAAAAJ&hl=en">Jongwoo Park</a>, 
              <a href="https://www3.cs.stonybrook.edu/~kkahatapitiy/">Kumara Kahatapitiya</a>,
              <a href="https://scholar.google.co.kr/citations?user=UsqNPH4AAAAJ&hl=ko"><strong>Donghyun Kim</strong></a>,
              <a href="https://shivchander.github.io"><strong>Shivchander Sudalairaj</strong></a>, 
              <a href="https://scholar.google.com/citations?user=kCxHiwUAAAAJ&hl=en">Quanfu Fan</a>, 
              <a href="http://michaelryoo.com">Michael S. Ryoo</a>
              <br>
              <em>IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</em>, 2024
              <br>
              <p>
                  Vision Transformers (ViTs) are state-of-the-art in computer vision, but pyramid architectures like Swin Transformer have overshadowed their advantages. This paper introduces GrafT, a simple, efficient add-on that enhances ViTs by leveraging global dependencies and multi-scale features throughout the network. GrafT delivers consistent improvements across various models, significantly boosting mobile-size models like DeiT-T (+3.9%) and MobileViT-XXS (+1.9%) on ImageNet-1k. 
              </p>
  
          </td>
      </tr>


          </tbody></table>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Inspired from <a href="https://github.com/jonbarron/jonbarron_website">JonBarron's website</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
